## 高层设计文档（High-level Design）

> 版本：v1.0  
> 更新时间：2025年 12月 16日 星期二 16:54:20 CST  
> 说明：本文件基于项目 README 的总体描述，总结关键模块设计思路、核心数据结构（概念模型）与关键流程，不包含任何具体代码实现。

---

### 1. 设计目标与原则

- **1.1 设计目标**  
  - 在工业现场环境中，稳定、高效地采集 OPC UA 数据，保证高可用与高数据完整性。  
  - 支持大规模 Tag 并发采集（至少 1000+ Tag），在可接受的资源消耗下满足实时性要求（采集延迟 \< 100ms）。  
  - 提供统一的数据访问与告警能力，为 EMS / Web 监控中心提供可靠的数据支撑。  

- **1.2 设计原则**  
  - **解耦与可扩展性**：通过消息队列与服务边界，将采集、处理、存储、服务对外暴露解耦，便于横向扩展。  
  - **高可用与冗余**：通过主备节点、分布式锁、消息副本与数据库主从等机制，减少单点故障影响。  
  - **配置驱动**：采集点、规则、数据路由等以配置为主，运行时无需修改代码即可调整。  
  - **可观测性优先**：从设计阶段考虑监控指标、日志、追踪与告警规则。  

---

### 2. 关键模块设计思路

#### 2.1 OPC UA 数据采集模块

- **职责**  
  - 管理与 OPC UA 网关（KepserverEx）之间的会话与订阅关系。  
  - 根据配置订阅多个 Tag 的数据变化，并在变化发生时将数据统一封装为数据点对象。  
  - 实现断线检测、重连、会话重建与订阅重建，确保数据连续性。  

- **功能拆分**  
  - 采集源管理：加载与维护多个 OPC UA Server 的连接配置。  
  - 订阅管理：按 Tag 分组创建订阅，控制采样周期、发布周期与死区策略。  
  - 数据缓冲：对高频数据进行合理缓冲与聚合，避免频繁写入消息队列。  
  - 主备协调：在多节点部署时配合高可用模块实现 Active / Standby 角色切换。  

#### 2.2 消息总线与数据路由模块

- **职责**  
  - 为采集模块与后端处理/存储模块提供统一的数据传输通道。  
  - 根据业务需要，将不同类型的数据路由到不同的 Kafka Topic。  

- **设计要点**  
  - Topic 规划：区分原始采集数据、清洗后数据、聚合指标等。  
  - 生产者策略：支持批量发送与失败重试，实现“至少一次”投递语义。  
  - 消费者策略：支持多消费者组并行处理，提高整体吞吐。  

#### 2.3 数据清洗与实时处理模块

- **职责**  
  - 对原始采集数据进行质量控制和格式标准化。  
  - 在数据到达时执行在线规则计算和基本聚合。  

- **功能拆分**  
  - 数据质量控制：异常值过滤、缺失值补偿、时间戳校正、质量标记校验。  
  - 单点转换规则：单位换算、标度变换、编码值翻译（如状态码→人类可读描述）。  
  - 窗口聚合：按时间窗口生成平均值、最大值、最小值等聚合指标。  

#### 2.4 存储层（Redis + MySQL）模块

- **职责**  
  - 为实时查询和告警提供低延迟数据访问能力。  
  - 为长周期数据分析和审计提供可靠的历史数据存储。  

- **Redis 设计思路**  
  - 以 Tag 为主键存储最新值及近期若干指标。  
  - 配置 TTL 控制数据生命周期，避免内存无限增长。  
  - 将热点 Tag 预加载在内存中，以提升常用查询性能。  

- **MySQL 设计思路**  
  - 按时间维度（如每月/每日）进行分表，以控制单表大小。  
  - 对常用查询维度（设备、Tag、时间区间）建立复合索引。  
  - 通过批量写入降低单条写入开销，提高吞吐能力。  

#### 2.5 数据服务与 API 模块

- **职责**  
  - 向上层 EMS / Web 系统提供统一的“数据查询 + 告警 + 统计”接口。  
  - 屏蔽存储层细节，为调用方提供稳定、易理解的业务语义接口。  

- **功能拆分**  
  - 历史查询接口：按 Tag + 时间范围返回时序数据，可附带聚合能力。  
  - 实时查询接口：返回 Tag 最新值与质量标记。  
  - 统计接口：返回按设备/产线/时间聚合后的统计指标。  
  - 告警接口：告警规则管理、告警事件查询、状态变更（确认/恢复）。  

#### 2.6 高可用与冗余模块

- **职责**  
  - 维护系统关键组件（采集节点、数据库、缓存等）的主备角色与健康状态。  
  - 在检测到故障时触发故障切换流程，确保整体服务不中断或最小中断。  

- **功能拆分**  
  - 状态管理：记录每个节点的角色、优先级与健康信息。  
  - 选主机制：基于分布式锁或类似机制保证单实例 Active。  
  - 故障检测：通过心跳与健康检查接口快速发现异常。  
  - 切换协调：在切换完成后通知相关模块更新依赖。  

#### 2.7 监控与告警模块

- **职责**  
  - 收集系统运行指标并可视化展示。  
  - 根据预设规则在出现异常时触发告警。  

- **功能拆分**  
  - 指标采集：系统级、应用级、业务级。  
  - 告警规则配置：延迟过高、队列积压、内存压力、数据完整性下降等。  
  - 告警分发：向运维人员或外部告警系统发送通知。  

---

### 3. 核心数据结构（概念模型）

> 以下为领域层面的抽象概念，用于指导实现，不对应具体代码结构。

- **DataSource（数据源）**  
  - 描述一个 OPC UA Server 实例及其连接属性（地址、认证方式等）。  

- **TagConfig（采集点配置）**  
  - 描述单个 Tag 的采集配置：NodeId、采样周期、发布周期、死区策略、所属设备/产线等。  

- **SubscriptionSession（订阅会话）**  
  - 表示采集节点与某一 OPC UA Server 之间的一组订阅上下文。  
  - 包含多个 Tag 的监控项、会话状态与重连策略。  

- **DataPoint（数据点）**  
  - 单次采集到的一条测点记录：数据源标识、节点标识、数值、设备时间戳、采集时间戳、质量标记、标签元数据等。  

- **CleaningRule（清洗规则）**  
  - 对单个 Tag 或一组 Tag 的数据清洗策略：阈值范围、平滑窗口、缺失值处理方式等。  

- **AggregationWindow（聚合窗口）**  
  - 定义某个时间窗口统计的范围与粒度（如 1 min / 5 min），以及需要执行的聚合函数集合。  

- **CacheEntry（缓存条目）**  
  - 描述存储在 Redis 中的一条或一组数据的结构，例如：最新值、最近若干值、统计信息等。  

- **QueryRequest（查询请求）**  
  - 封装来自上层的查询条件：Tag 列表、时间区间、聚合类型、分页信息、过滤条件等。  

- **QueryResult（查询结果）**  
  - 返回给调用方的查询结果：数据点列表、聚合值、单位与元数据等。  

- **AlertRule（告警规则）**  
  - 定义告警触发条件：监控对象、阈值条件、持续时间、告警级别、抑制策略等。  

- **AlertEvent（告警事件）**  
  - 告警规则在运行时被触发后的事件实例：发生时间、关联对象、当前状态（激活/确认/恢复）、相关上下文。  

- **NodeInfo（节点信息）**  
  - 描述系统中一个节点（采集节点、服务实例等）的基本信息：ID、角色、优先级、健康状态、最近心跳时间等。  

- **FailoverEvent（故障切换事件）**  
  - 描述一次从检测故障到完成主备切换的完整过程：起因、步骤、影响范围、结果等。  

---

### 4. 关键业务与系统流程（无代码）

#### 4.1 实时采集与上送流程

1. 系统从配置加载所有 `DataSource` 与 `TagConfig`。  
2. 为每个 `DataSource` 建立 OPC UA 会话并创建订阅（包含多个监控项）。  
3. 当 Tag 发生变化时，OPC UA 网关向对应订阅推送新数据。  
4. 采集模块将新数据封装为 `DataPoint` 对象，并进入本地缓冲。  
5. 缓冲模块按照配置（如时间或数量阈值）将 `DataPoint` 批量发送至 Kafka 对应 Topic。  

#### 4.2 数据清洗与持久化流程

1. 清洗模块从原始数据 Topic 中连续消费 `DataPoint`。  
2. 根据 `CleaningRule` 对数据执行质量检查和转换操作。  
3. 合格数据写入新的 Topic 或直接写入 Redis / MySQL。  
4. 批量写入模块周期性地从中间缓冲读取数据，按照表分区策略写入 MySQL。  
5. 写入成功后，必要时更新 Redis 中的最新值或统计缓存。  

#### 4.3 告警检测与处理流程

1. 告警模块从实时计算结果或 Redis 中获取目标指标的最新值。  
2. 将实时数据与对应的 `AlertRule` 进行匹配，判断是否满足触发条件。  
3. 若满足条件，则创建或更新相应的 `AlertEvent`，记录当前状态并持久化。  
4. 将告警事件推送给上层 EMS / 通知系统，供人员确认与处理。  
5. 在后续数据恢复正常或规则条件不再满足时，自动或人工将 `AlertEvent` 状态更新为恢复。  

#### 4.4 高可用主备切换流程（采集节点）

1. Active 与 Standby 节点周期性上报 `NodeInfo` 并尝试续约 `LeaderLock`。  
2. 如果 Standby 检测到 Active 心跳超时或 `LeaderLock` 失效，则尝试抢占锁。  
3. 抢锁成功后，Standby 切换为新的 Active，开始对 Kafka 进行数据写入。  
4. 其他依赖采集节点的服务通过订阅 `FailoverEvent` 或检查状态获取新的主节点信息。  

#### 4.5 查询与统计流程

1. 上层 EMS / Web 通过 API 调用发送 `QueryRequest`。  
2. 数据服务层根据请求内容先访问 Redis（命中则直接返回），未命中时访问 MySQL。  
3. 如需聚合计算，服务层在数据加载后在内存中或通过数据库聚合生成结果。  
4. 将最终 `QueryResult` 返回给调用方。  

---

### 5. 设计边界与后续扩展

- **当前版本不包含的内容**  
  - 具体类图与时序图（可在后续详细设计文档中补充）。  
  - 具体 C++ 接口与模块间的头文件定义。  
  - 机器学习/预测性维护等高级分析模块的详细设计。  

- **可预期扩展方向**  
  - 引入集中配置中心，支持运行时动态下发采集与告警配置。  
  - 增加多租户与权限管理能力，支持按业务线/工厂隔离数据。  
  - 扩展更多工业协议接入，通过在网关层或采集层增加适配器实现。  


