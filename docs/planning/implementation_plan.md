## 任务计划文档（Implementation Plan）

> 版本：v1.1  
> 更新时间：2025年 12月 16日 星期二 17:22:25 CST  
> 说明：本文件将项目拆分为多个阶段及子任务，每个阶段都明确预期目标和可检验的结果产出，便于规划与验收。

---

### 阶段 0：需求澄清与架构方案冻结

- **目标**：统一对业务场景、系统边界和非功能性指标的理解，产出稳定的架构与高层设计文档。  
- **主要任务：**  
  - **业务需求梳理**：  
    - 明确接入的工厂/产线数量与类型。  
    - 统计初期需要接入的设备与 Tag 数量及采样周期。  
  - **非功能性需求确认**：  
    - 目标吞吐量、延迟、可用性、数据保留时长等指标。  
  - **架构与设计评审**：  
    - 基于现有 README 与本次生成的架构/设计文档，召开评审会议并冻结方案。  
  - **配置基线建立**：  
    - 初版设备-Tag 映射表与采集配置样例（小规模）。  

- **可检验结果：**  
  - 《系统架构文档》v1.0 经评审通过并归档。  
  - 《高层设计文档》v1.0 经评审通过并归档。  
  - 一份确定的 Tag 列表与非功能性指标（例如：1000+ Tag、采样周期 1s、数据保留 6 个月等）。  

---

### 阶段 1：最小可用采集链路（MVP Ingestion）

- **目标**：打通“现场设备 → OPC UA 网关 → 采集节点 → Kafka”的最小可用链路，实现小规模 Tag 的稳定采集与上送。  

- **主要任务：**  
  - **open62541 Client 构建与验证：**  
    - 基于 open62541 在本地编译最小可用 OPC UA Client（含 CMake 工程）。  
    - 通过配置文件加载 endpoint / 安全模式 / 证书（若有）。  
    - 使用 Read/Write 方法对单一 NodeId 做连通性与权限测试。  
  - **连接与会话管理（KepserverEx 测试环境）：**  
    - 与测试环境 KepserverEx 建立会话，验证会话创建、激活、心跳保持。  
    - 在网络闪断/重连场景下验证会话恢复。  
  - **订阅与监控项验证：**  
    - 通过配置订阅 10–50 个示例 Tag，验证创建/删除订阅与监控项。  
    - 校验采样周期/发布周期/死区策略在网关侧与 Client 侧的生效情况。  
  - **数据点封装与发送链路：**  
    - 将采集到的变化封装为 `DataPoint`（概念模型）并写入 Kafka `opcua-data`。  
    - 启用批量发送/重试策略，验证“至少一次”语义。  
  - **基础调试与监控：**  
    - 提供最小命令行工具：消费 `opcua-data`，打印示例 Tag 的实时值与质量。  
    - 记录端到端延迟基线（Tag 变化 → Kafka 入队）。  

- **可检验结果：**  
  - 成功构建并运行基于 open62541 的最小 Client；能对目标节点做 Read/Write 测试。  
  - 订阅的 10–50 个示例 Tag 持续产生变化并进入 Kafka `opcua-data`。  
  - 输出《MVP 采集链路验证报告》，包含：  
    - 示例 Tag 列表与节点属性。  
    - 连通性与断线重连验证结果。  
    - 端到端延迟与初步吞吐数据。  
    - 已发现的问题与改进项。  

---

### 阶段 2：数据清洗与基础持久化

- **目标**：在保证基础采集稳定的前提下，完成数据清洗、缓存与数据库持久化能力，实现可查询的历史数据。  

- **主要任务：**  
  - **清洗规则框架搭建：**  
    - 以配置驱动定义 `CleaningRule`（阈值、范围、单位换算、质量过滤）。  
    - 支持规则热加载 / 重载，不重启服务即可生效。  
  - **数据质量与时间线校正：**  
    - 对乱序/缺失/重复数据执行去重与插值策略（概念验证级别）。  
    - 设备时间戳与采集时间戳的比对与校正策略验证。  
  - **Redis 缓存集成：**  
    - 设计 `CacheEntry` 键结构、TTL 与逐出策略。  
    - 将最新值与近一小段时间窗口的关键指标写入 Redis，并验证命中率。  
  - **MySQL 分表与批量写入：**  
    - 设计时间分表方案与复合索引（设备/Tag + 时间）。  
    - 实现 `BatchFlushTask`（如每 5 秒批量写入，单批 500–1000 条）并做写入压力测试。  
  - **基础查询接口（原型）：**  
    - 提供 REST 原型接口：按 Tag + 时间范围查询；可返回原始与简单聚合。  
    - 支持从 Redis 命中失败时回源 MySQL，并记录命中率。  

- **可检验结果：**  
  - MySQL 中可查询到分表后的历史数据，并与 Kafka 输入数据量对账。  
  - 通过 API/脚本拉取 Tag 历史曲线，验证正确性与时间顺序。  
  - 输出《数据清洗与持久化验证报告》，包含：  
    - 清洗规则示例及效果。  
    - 批量写入的吞吐与 P95/P99 延迟。  
    - Redis 命中率与回源比例。  

---

### 阶段 3：高可用与主备切换能力

- **目标**：为采集层和核心存储层引入高可用与主备切换机制，确保在单点故障情况下系统仍可持续提供服务。  

- **主要任务：**  
  - **采集节点主备机制实现：**  
    - 设计 `NodeInfo` 与 `LeaderLock` 概念模型。  
    - 实现 Active / Standby 节点的心跳上报、锁抢占与状态切换逻辑。  
  - **故障检测与自动重连：**  
    - 为 OPC UA 会话、Kafka 生产者、Redis/MySQL 连接实现重试与重连策略。  
  - **基础存储高可用拓扑搭建：**  
    - 配置 Kafka 多副本、Redis 主从、MySQL 主从或集群。  
    - 明确故障切换流程（手动 / 半自动 / 全自动）。  
  - **故障演练机制：**  
    - 编写网络中断、主机宕机、进程异常退出等场景的演练脚本。  

- **可检验结果：**  
  - 在测试环境中，通过故障演练可以验证：  
    - 主采集节点宕机后，Standby 在约定时间内（如 \< 5 秒）自动接管并继续写入 Kafka。  
    - Kafka / Redis / MySQL 在单节点故障下不影响服务可用性或影响在可接受范围内。  
  - 输出《高可用与故障演练报告》，包含每类演练场景的步骤、结果与结论。  

---

### 阶段 4：高级告警与统计分析能力

- **目标**：在稳定的数据链路和存储之上，构建业务可感知的告警与统计分析能力。  

- **主要任务：**  
  - **告警规则引擎：**  
    - 设计 `AlertRule` 与 `AlertEvent` 概念模型。  
    - 支持阈值、区间、速率变化等基础规则类型。  
  - **告警服务：**  
    - 实现告警规则的创建、修改、启停接口。  
    - 实现告警事件的生命周期管理（触发、确认、恢复）。  
  - **统计分析服务：**  
    - 实现按产线/设备/时间范围的聚合统计接口。  
    - 支持生成基础的报表数据供前端或 BI 工具使用。  
  - **与 EMS / Web 前端集成：**  
    - 提供 HTTP / WebSocket 接口，支持实时告警推送与历史告警查询。  

- **可检验结果：**  
  - 在测试环境中配置至少 3 类告警规则，能够通过模拟数据成功触发与恢复。  
  - 在前端/可视化界面中可以查看告警列表、明细和统计图表。  
  - 输出《告警与统计功能验收报告》，包含：  
    - 规则覆盖范围；  
    - 告警准确率与误报/漏报分析；  
    - 典型统计报表示例。  

---

### 阶段 5：监控、告警与运维自动化

- **目标**：完善系统的可观测性与运维能力，确保系统在生产环境中可稳定运行、可快速诊断问题。  

- **主要任务：**  
  - **监控体系搭建：**  
    - 为各服务暴露统一的指标端点（如 Prometheus metrics）。  
    - 建立系统级、应用级、业务级的监控看板。  
  - **系统告警规则完善：**  
    - 在 `alerting/rules.yaml` 中增加 CPU/内存/磁盘/网络、Kafka 积压、Redis 内存、数据库连接数等告警规则。  
  - **运维自动化：**  
    - 编写一键部署脚本（Docker Compose / CI Pipeline 集成）。  
    - 提供常用运维操作脚本（启动/停止、备份/恢复、扩容/缩容等）。  

- **可检验结果：**  
  - 在监控平台（如 Grafana）中可以查看关键指标并进行实时监控。  
  - 在压力测试或故障演练中，相关系统告警能够按预期触发并通知到位。  
  - 输出《运维与监控体系说明文档》与一套可执行的运维脚本。  

---

### 阶段 6：性能优化与长期稳定性验证

- **目标**：在完成功能与高可用能力后，通过系统化的性能与稳定性测试，验证系统在目标负载下的表现，并进行必要的优化。  

- **主要任务：**  
  - **性能压测：**  
    - 设计多种负载场景（不同 Tag 数量、采样频率、并发查询量）。  
    - 记录在各场景下的吞吐量、延迟、资源占用情况。  
  - **瓶颈分析与优化：**  
    - 使用 Profiling、链路追踪等手段定位热点模块。  
    - 针对 CPU、内存、磁盘 IO、网络等瓶颈制定优化策略。  
  - **长期稳定性测试：**  
    - 运行 7×24 小时长稳测试，监控内存泄漏、连接稳定性、数据丢失/重复等问题。  

- **可检验结果：**  
  - 输出《性能测试报告》，包含：  
    - 各负载场景下的 TPS/QPS、P95/P99 延迟、资源使用曲线。  
  - 输出《稳定性测试报告》，确认：  
    - 采集延迟满足 \< 100ms；  
    - 吞吐量满足 ≥ 10k msg/s；  
    - 可用性接近或达到 99.95% 目标；  
    - 数据完整性达到 ≥ 99.99%。  

---

### 阶段 7：经验沉淀与持续改进

- **目标**：在系统稳定运行后，总结实践经验，持续优化架构与开发流程。  

- **主要任务：**  
  - 整理典型问题与案例，形成知识库。  
  - 评估是否需要引入新的能力（如预测性维护、异常检测算法等）。  
  - 根据业务反馈迭代架构与设计文档，保持文档与实现同步。  

- **可检验结果：**  
  - 更新后的《架构文档》《设计文档》《任务计划》版本（v2.x+）。  
  - 一套可复用的项目模板与最佳实践清单。  


